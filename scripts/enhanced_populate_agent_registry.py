#!/usr/bin/env python3
"""
Enhanced script to populate the Agent Registry DynamoDB table with realistic mock data.
This version includes better Strands SDK integration patterns and real agent metrics collection.
"""

import boto3
import json
from datetime import datetime, timezone, timedelta
import random
from decimal import Decimal
from typing import Dict, Any, List
import os
from pathlib import Path

# Configuration
TABLE_NAME = "trade-matching-system-agent-registry-production"
REGION = "us-east-1"

# Strands SDK Agent definitions matching actual deployment
STRANDS_AGENTS = [
    {
        "agent_id": "pdf_adapter_agent",
        "agent_type": "PDF_ADAPTER",
        "agent_name": "PDF Adapter",
        "base_latency": 15000,  # PDF processing is slower
        "base_throughput": 25,
        "base_error_rate": 0.015,
        "tools": ["download_pdf_from_s3", "extract_text_with_bedrock", "save_canonical_output"],
        "description": "Downloads PDFs from S3 and extracts text using Bedrock multimodal",
        "system_prompt": "You are a PDF processing agent specialized in extracting text from trade confirmation documents.",
        "model_provider": "amazon.nova-pro-v1:0",
        "deployment_path": "deployment/pdf_adapter/pdf_adapter_agent_strands.py",
        "handoff_targets": ["trade_extraction_agent"],
        "typical_cycles": (2, 4),  # Min, Max cycles
        "tool_usage_patterns": {
            "download_pdf_from_s3": 1.0,  # Always used
            "extract_text_with_bedrock": 1.0,  # Always used
            "save_canonical_output": 1.0,  # Always used
        }
    },
    {
        "agent_id": "trade_extraction_agent", 
        "agent_type": "TRADE_EXTRACTOR",
        "agent_name": "Trade Extraction",
        "base_latency": 8000,   # Text extraction is fast
        "base_throughput": 45,
        "base_error_rate": 0.008,
        "tools": ["use_aws", "store_trade_in_dynamodb"],
        "description": "Extracts structured trade data from canonical output",
        "system_prompt": "You are a trade data extraction agent that converts unstructured text into structured trade records.",
        "model_provider": "amazon.nova-pro-v1:0",
        "deployment_path": "deployment/trade_extraction/trade_extraction_agent_strands.py",
        "handoff_targets": ["trade_matching_agent"],
        "typical_cycles": (3, 6),
        "tool_usage_patterns": {
            "use_aws": 0.8,  # Usually used for S3 operations
            "store_trade_in_dynamodb": 1.0,  # Always used
        }
    },
    {
        "agent_id": "trade_matching_agent",
        "agent_type": "TRADE_MATCHER", 
        "agent_name": "Trade Matching",
        "base_latency": 12000,  # Matching logic takes time
        "base_throughput": 35,
        "base_error_rate": 0.012,
        "tools": ["scan_trades_table", "save_matching_report"],
        "description": "Matches trades by attributes across bank and counterparty tables",
        "system_prompt": "You are a trade matching agent that finds corresponding trades across different systems using fuzzy matching.",
        "model_provider": "amazon.nova-pro-v1:0",
        "deployment_path": "deployment/trade_matching/trade_matching_agent_strands.py",
        "handoff_targets": ["exception_manager"],
        "typical_cycles": (4, 8),
        "tool_usage_patterns": {
            "scan_trades_table": 1.0,  # Always used
            "save_matching_report": 1.0,  # Always used
        }
    },
    {
        "agent_id": "exception_manager",
        "agent_type": "EXCEPTION_HANDLER",
        "agent_name": "Exception Handler",
        "base_latency": 3000,   # Exception handling is fast
        "base_throughput": 60,
        "base_error_rate": 0.005,
        "tools": ["get_severity_guidelines", "store_exception_record"],
        "description": "Analyzes exceptions and determines severity with SLA tracking",
        "system_prompt": "You are an exception management agent that classifies and prioritizes trade processing exceptions.",
        "model_provider": "amazon.nova-pro-v1:0",
        "deployment_path": "deployment/exception_management/exception_management_agent_strands.py",
        "handoff_targets": [],  # Terminal agent
        "typical_cycles": (2, 3),
        "tool_usage_patterns": {
            "get_severity_guidelines": 1.0,  # Always used
            "store_exception_record": 1.0,  # Always used
        }
    },
    {
        "agent_id": "orchestrator_otc",
        "agent_type": "ORCHESTRATOR",
        "agent_name": "Orchestrator",
        "base_latency": 2000,   # Orchestration is very fast
        "base_throughput": 80,
        "base_error_rate": 0.003,
        "tools": ["use_aws", "scan_trades_table"],
        "description": "Coordinates agent handoffs and monitors SLA compliance",
        "system_prompt": "You are an orchestrator agent that coordinates multi-agent workflows and monitors system performance.",
        "model_provider": "amazon.nova-pro-v1:0",
        "deployment_path": "deployment/orchestrator/orchestrator_agent_strands.py",
        "handoff_targets": ["pdf_adapter_agent", "trade_extraction_agent", "trade_matching_agent"],
        "typical_cycles": (1, 2),
        "tool_usage_patterns": {
            "use_aws": 0.9,  # Usually used
            "scan_trades_table": 0.7,  # Sometimes used
        }
    }
]


def generate_strands_metrics(agent_config: Dict[str, Any]) -> Dict[str, Any]:
    """Generate realistic Strands SDK metrics with proper variation."""
    base_latency = agent_config["base_latency"]
    base_throughput = agent_config["base_throughput"] 
    base_error_rate = agent_config["base_error_rate"]
    
    # Add realistic variation (Â±20%)
    latency_variation = random.uniform(0.8, 1.2)
    throughput_variation = random.uniform(0.8, 1.2)
    error_variation = random.uniform(0.5, 1.5)
    
    # Calculate realistic token usage based on agent type and cycles
    min_cycles, max_cycles = agent_config["typical_cycles"]
    avg_cycles = random.randint(min_cycles, max_cycles)
    
    # Token usage varies by agent complexity
    if agent_config["agent_type"] == "PDF_ADAPTER":
        base_tokens_per_cycle = random.randint(3000, 6000)  # OCR is token-intensive
    elif agent_config["agent_type"] == "TRADE_EXTRACTOR":
        base_tokens_per_cycle = random.randint(2000, 4000)  # Structured extraction
    elif agent_config["agent_type"] == "TRADE_MATCHER":
        base_tokens_per_cycle = random.randint(4000, 8000)  # Complex comparison logic
    elif agent_config["agent_type"] == "EXCEPTION_HANDLER":
        base_tokens_per_cycle = random.randint(1500, 3000)  # Classification logic
    else:  # ORCHESTRATOR
        base_tokens_per_cycle = random.randint(1000, 2000)  # Coordination logic
    
    total_tokens = base_tokens_per_cycle * avg_cycles
    input_tokens = int(total_tokens * 0.75)  # 75% input, 25% output typical for reasoning
    output_tokens = total_tokens - input_tokens
    
    # Calculate tool metrics based on usage patterns
    tool_calls = 0
    tool_success_count = 0
    for tool_name, usage_probability in agent_config["tool_usage_patterns"].items():
        if random.random() < usage_probability:
            calls = random.randint(1, 3)  # 1-3 calls per tool per execution
            tool_calls += calls
            # Tools are generally more reliable than overall agent success
            tool_success_count += int(calls * max(0.95, 1.0 - (base_error_rate * 0.5)))
    
    tool_success_rate = tool_success_count / tool_calls if tool_calls > 0 else 1.0
    
    return {
        "avg_latency_ms": int(base_latency * latency_variation),
        "throughput_per_hour": int(base_throughput * throughput_variation),
        "error_rate": Decimal(str(round(min(0.05, base_error_rate * error_variation), 4))),
        "total_tokens": total_tokens,
        "input_tokens": input_tokens,
        "output_tokens": output_tokens,
        "avg_cycles": avg_cycles,
        "avg_cycle_time_ms": random.randint(800, 2500),  # Time per reasoning cycle
        "tool_calls": tool_calls,
        "tool_success_rate": Decimal(str(round(tool_success_rate, 4))),
        "success_rate": Decimal(str(round(max(0.90, 1.0 - (base_error_rate * error_variation)), 4))),
        "active_tasks": random.randint(0, 5),
        "cache_hit_rate": Decimal(str(round(random.uniform(0.15, 0.35), 4))),
        "model_provider": agent_config["model_provider"],
        "handoff_count": len(agent_config["handoff_targets"]),
        "deployment_status": "ACTIVE",
    }


def create_enhanced_agent_record(agent_config: Dict[str, Any]) -> Dict[str, Any]:
    """Create a comprehensive agent registry record with Strands SDK metadata."""
    metrics = generate_strands_metrics(agent_config)
    
    # Simulate recent heartbeat (within last 2 minutes for healthy agents)
    heartbeat_age = random.randint(10, 120)  # 10 seconds to 2 minutes
    last_heartbeat = datetime.now(timezone.utc) - timedelta(seconds=heartbeat_age)
    
    return {
        "agent_id": agent_config["agent_id"],
        "agent_name": agent_config["agent_name"],
        "agent_type": agent_config["agent_type"],
        "deployment_status": "ACTIVE",
        "last_heartbeat": last_heartbeat.isoformat().replace("+00:00", "Z"),
        "description": agent_config["description"],
        "tools": agent_config["tools"],
        "system_prompt": agent_config["system_prompt"],
        "deployment_path": agent_config["deployment_path"],
        "handoff_targets": agent_config["handoff_targets"],
        **metrics
    }


def verify_agent_deployment_files() -> List[str]:
    """Verify that actual Strands agent deployment files exist."""
    missing_files = []
    for agent in STRANDS_AGENTS:
        deployment_path = Path(agent["deployment_path"])
        if not deployment_path.exists():
            missing_files.append(str(deployment_path))
    return missing_files


def populate_enhanced_table():
    """Populate the DynamoDB table with enhanced Strands agent data."""
    try:
        # Verify deployment files exist
        missing_files = verify_agent_deployment_files()
        if missing_files:
            print("âš ï¸  Warning: Some agent deployment files are missing:")
            for file in missing_files:
                print(f"  - {file}")
            print("Continuing with mock data generation...\n")
        
        # Initialize DynamoDB client
        dynamodb = boto3.resource('dynamodb', region_name=REGION)
        table = dynamodb.Table(TABLE_NAME)
        
        print(f"Populating {TABLE_NAME} with enhanced Strands agent data...")
        print(f"Region: {REGION}")
        print(f"Agents: {len(STRANDS_AGENTS)}\n")
        
        # Create and insert agent records
        for agent_config in STRANDS_AGENTS:
            record = create_enhanced_agent_record(agent_config)
            
            print(f"ğŸ“Š {record['agent_id']} ({agent_config['agent_type']}):")
            print(f"  â”œâ”€ Name: {record['agent_name']}")
            print(f"  â”œâ”€ Description: {record['description']}")
            print(f"  â”œâ”€ Tools: {', '.join(record['tools'])}")
            print(f"  â”œâ”€ Handoff Targets: {', '.join(record['handoff_targets']) if record['handoff_targets'] else 'None (terminal)'}")
            print(f"  â”œâ”€ Performance:")
            print(f"  â”‚  â”œâ”€ Latency: {record['avg_latency_ms']}ms")
            print(f"  â”‚  â”œâ”€ Throughput: {record['throughput_per_hour']}/hr")
            print(f"  â”‚  â”œâ”€ Success Rate: {float(record['success_rate']):.1%}")
            print(f"  â”‚  â””â”€ Error Rate: {float(record['error_rate']):.2%}")
            print(f"  â”œâ”€ Strands Metrics:")
            print(f"  â”‚  â”œâ”€ Cycles: {record['avg_cycles']} avg ({record['avg_cycle_time_ms']}ms/cycle)")
            print(f"  â”‚  â”œâ”€ Tokens: {record['total_tokens']:,} ({record['input_tokens']:,} in / {record['output_tokens']:,} out)")
            print(f"  â”‚  â”œâ”€ Tool Calls: {record['tool_calls']} (success: {float(record['tool_success_rate']):.1%})")
            print(f"  â”‚  â””â”€ Cache Hit Rate: {float(record['cache_hit_rate']):.1%}")
            print(f"  â””â”€ Model: {record['model_provider']}")
            
            # Insert into DynamoDB
            table.put_item(Item=record)
            print(f"  âœ… Stored successfully\n")
            
        print(f"ğŸ‰ Successfully populated {len(STRANDS_AGENTS)} enhanced agent records!")
        print(f"ğŸŒ View results: http://localhost:3000")
        print(f"ğŸ“Š Dashboard: Agent Health Panel")
        print(f"ğŸ” Real-time monitoring available")
        
        # Enhanced verification with detailed metrics
        print(f"\nğŸ” Verifying data insertion with metrics...")
        total_tokens = 0
        total_throughput = 0
        
        for agent_config in STRANDS_AGENTS:
            try:
                response = table.get_item(Key={"agent_id": agent_config["agent_id"]})
                if "Item" in response:
                    item = response["Item"]
                    total_tokens += int(item.get("total_tokens", 0))
                    total_throughput += int(item.get("throughput_per_hour", 0))
                    print(f"  âœ… {agent_config['agent_id']}: Verified (tokens: {item.get('total_tokens', 0):,})")
                else:
                    print(f"  âŒ {agent_config['agent_id']}: Not found after insertion")
            except Exception as verify_error:
                print(f"  âš ï¸  {agent_config['agent_id']}: Verification failed - {verify_error}")
        
        print(f"\nğŸ“ˆ System Totals:")
        print(f"  â”œâ”€ Total Token Usage: {total_tokens:,}")
        print(f"  â”œâ”€ Combined Throughput: {total_throughput}/hr")
        print(f"  â””â”€ Active Agents: {len(STRANDS_AGENTS)}")
        
    except Exception as e:
        print(f"âŒ Error populating enhanced table: {e}")
        print(f"Troubleshooting checklist:")
        print(f"  1. AWS credentials configured: aws configure list")
        print(f"  2. DynamoDB table exists: aws dynamodb describe-table --table-name {TABLE_NAME}")
        print(f"  3. Write permissions: Check IAM policy")
        print(f"  4. Region correct: {REGION}")


if __name__ == "__main__":
    populate_enhanced_table()