{
  "enabled": true,
  "name": "Strands Agent Intelligence Check",
  "description": "Ensures Strands SDK agents fully leverage LLM intelligence by avoiding over-prescriptive tools, rigid workflows, and manual orchestration. Promotes goal-oriented prompts and flexible tool design.",
  "version": "1",
  "when": {
    "type": "fileEdited",
    "patterns": [
      "**/*agent*strands*.py",
      "deployment/**/*agent*.py",
      "**/agents/**/*.py"
    ]
  },
  "then": {
    "type": "askAgent",
    "prompt": "Review this Strands SDK agent code to ensure it fully leverages LLM intelligence:\n\n## Anti-Patterns to Avoid\n\n1. **Over-Prescriptive Tools**: Tools that are too specific and force a linear workflow\n   - ❌ BAD: `download_pdf()`, `extract_text()`, `save_output()` (3 rigid steps)\n   - ✅ GOOD: `process_document()`, `save_canonical_output()` (flexible, high-level)\n\n2. **Manual Orchestration**: Telling the agent exactly what to do step-by-step\n   - ❌ BAD: \"First download, then extract, then save\"\n   - ✅ GOOD: \"Process this document and create canonical output\"\n\n3. **Rigid Prompts**: Prompts that prescribe the exact workflow\n   - ❌ BAD: \"Step 1: Do X. Step 2: Do Y. Step 3: Do Z.\"\n   - ✅ GOOD: \"Your goal is X. You have tools Y and Z. Decide the best approach.\"\n\n4. **Missing Error Recovery**: No ability for the agent to reason about failures\n   - ❌ BAD: Tools that just return errors without context\n   - ✅ GOOD: Tools that return rich error information the agent can reason about\n\n5. **Underutilizing Built-in Tools**: Not using powerful tools like `use_aws`\n   - ❌ BAD: Creating custom S3/Bedrock tools when `use_aws` exists\n   - ✅ GOOD: Leveraging `use_aws` for AWS operations\n\n6. **Low Temperature**: Using temperature too low (< 0.2) prevents reasoning\n   - ❌ BAD: `temperature=0.0` or `temperature=0.1`\n   - ✅ GOOD: `temperature=0.2` to `0.3` for reasoning while maintaining consistency\n\n## Best Practices\n\n1. **Goal-Oriented Prompts**: Tell the agent WHAT to achieve, not HOW\n2. **High-Level Tools**: Tools should represent capabilities, not steps\n3. **Rich Context**: Provide the agent with all information to make decisions\n4. **Error Reasoning**: Let the agent analyze errors and decide next steps\n5. **Flexible Workflows**: Agent should adapt based on the situation\n6. **Appropriate Temperature**: Balance consistency with reasoning ability\n\n## Review Checklist\n\n- [ ] Are tools high-level and flexible (not step-by-step)?\n- [ ] Does the prompt describe goals, not procedures?\n- [ ] Can the agent reason about errors and adapt?\n- [ ] Is `use_aws` leveraged for AWS operations?\n- [ ] Is temperature set appropriately (0.2-0.3 for reasoning tasks)?\n- [ ] Does the system prompt encourage decision-making?\n- [ ] Are tools well-documented so the agent understands their purpose?\n\nIf any anti-patterns are found, suggest refactoring to make the agent more intelligent and autonomous."
  }
}
